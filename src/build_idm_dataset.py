# build_idm_dataset.py
#
# Î£Ï…Î½Î´Î­ÎµÎ¹:
#   - HEnEx DAM Î±ÏÏ‡ÎµÎ¯Î± (Î·Î¼ÎµÏÎ®ÏƒÎ¹Î± Î±Î³Î¿ÏÎ¬)
#   - HEnEx IDM Î±ÏÏ‡ÎµÎ¯Î± (IDA1 / IDA2 / IDA3)
#   - Weather features (Î±Ï€ÏŒ Open-Meteo)
#
# ÎºÎ±Î¹ Ï†Ï„Î¹Î¬Ï‡Î½ÎµÎ¹ Î­Î½Î± ÎµÎ½Î¹Î±Î¯Î¿ CSV Î³Î¹Î± training Î¼Î¿Î½Ï„Î­Î»Ï‰Î½.
#
# Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ:
# - Î”ÎµÎ½ Ï€ÎµÎ¹ÏÎ¬Î¶Î¿Ï…Î¼Îµ ÎšÎ‘Î˜ÎŸÎ›ÎŸÎ¥ Ï„Î± column names Ï„Ï‰Î½ IDA Î±ÏÏ‡ÎµÎ¯Ï‰Î½.
# - Î¤Î± DAM columns Î¼Ï€Î±Î¯Î½Î¿Ï…Î½ Î¼Îµ prefix "DAM_" (ÎµÎºÏ„ÏŒÏ‚ Î±Ï€ÏŒ DELIVERY_MTU).
# - Î¤Î± weather columns Î¼Î­Î½Î¿Ï…Î½ ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿ CSV.
#
# Run:
#   python src/build_idm_dataset.py \
#       --results_root data/raw/henex/Results2024 \
#       --weather_csv data/processed/weather_features_15T_2024-06-16_2024-12-31.csv \
#       --start_date 2024-06-16 \
#       --end_date 2024-12-31 \
#       --out data/processed/idm_dataset_2024.csv

import argparse
import os
from datetime import datetime, date

import pandas as pd


# ---------- Helpers ----------

def parse_fname_date(fname: str) -> date | None:
    """
    Î Î±Î¯ÏÎ½ÎµÎ¹ filename Ï€.Ï‡. '20240616_EL-DAM_Results_EN_v01.xlsx'
    ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ date(2024,6,16).
    """
    try:
        base = os.path.basename(fname)
        d_str = base[:8]
        return datetime.strptime(d_str, "%Y%m%d").date()
    except Exception:
        return None


def load_dam_folder(dam_folder: str,
                    start_date: date,
                    end_date: date) -> pd.DataFrame:
    """
    Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ ÎŸÎ›Î‘ Ï„Î± DAM Î±ÏÏ‡ÎµÎ¯Î± ÏƒÏ„Î¿ dam_folder, Ï†Î¹Î»Ï„ÏÎ¬ÏÎµÎ¹ ÏƒÏ„Î¿ date range
    ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹:
        columns: ['DELIVERY_MTU', <ÏŒÎ»Î± Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± Î¼Îµ prefix DAM_>]
    """
    print(f"ğŸ“‚ Loading DAM from {dam_folder}")
    all_frames: list[pd.DataFrame] = []

    files = sorted(
        f for f in os.listdir(dam_folder)
        if f.endswith(".xlsx")
    )

    print(f"  â†’ Found {len(files)} DAM files")

    for fname in files:
        fdate = parse_fname_date(fname)
        if fdate is None:
            continue
        # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¿Ï…Î¼Îµ Î¼Îµ Î²Î¬ÏƒÎ· filename date (Î·Î¼Î­ÏÎ± Ï€Î±ÏÎ¬Î´Î¿ÏƒÎ·Ï‚)
        if fdate < start_date or fdate > end_date:
            continue

        full_path = os.path.join(dam_folder, fname)
        print(f"    â€¢ Reading DAM file: {fname}")
        df = pd.read_excel(full_path, engine="openpyxl")

        # Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ DELIVERY_MTU, Î´ÎµÎ½ Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± ÎºÎ¬Î½Î¿Ï…Î¼Îµ merge
        if "DELIVERY_MTU" not in df.columns:
            print(f"      âš ï¸ No DELIVERY_MTU in {fname}, skipping.")
            continue

        # Î£Îµ datetime
        df["DELIVERY_MTU"] = pd.to_datetime(df["DELIVERY_MTU"], errors="coerce")
        df = df.dropna(subset=["DELIVERY_MTU"])

        # Î•Ï€Î¹Ï€Î»Î­Î¿Î½ Ï†Î¯Î»Ï„ÏÎ¿ Î¼Îµ Î²Î¬ÏƒÎ· Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ® Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±
        d_col = df["DELIVERY_MTU"].dt.date
        df = df[(d_col >= start_date) & (d_col <= end_date)]

        if df.empty:
            continue

        all_frames.append(df)

    if not all_frames:
        print("  ğŸ” Raw DAM rows: 0")
        return pd.DataFrame(columns=["DELIVERY_MTU"])

    dam = pd.concat(all_frames, ignore_index=True)
    print(f"  ğŸ” Raw DAM rows: {len(dam)}")

    # Î’Î¬Î¶Î¿Ï…Î¼Îµ prefix DAM_ ÏƒÎµ ÏŒÎ»Î± Ï„Î± columns ÎµÎºÏ„ÏŒÏ‚ Î±Ï€ÏŒ DELIVERY_MTU
    rename_map = {
        c: f"DAM_{c}"
        for c in dam.columns
        if c != "DELIVERY_MTU"
    }
    dam = dam.rename(columns=rename_map)

   # --- Fix: group only numeric columns ---
    numeric_cols = dam.select_dtypes(include=["number"]).columns.tolist()

    agg_dict = {c: "mean" for c in numeric_cols}

    dam_grouped = (
        dam.groupby("DELIVERY_MTU", as_index=False)
       .agg(agg_dict)
    )


    print(
        f"  âœ… After grouping: rows = {len(dam_grouped)} | "
        f"unique MTUs = {dam_grouped['DELIVERY_MTU'].nunique()}"
    )
    return dam_grouped


def load_ida_folder(folder: str,
                    auction_name: str,
                    start_date: date,
                    end_date: date) -> pd.DataFrame:
    """
    Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ ÎŸÎ›Î‘ Ï„Î± IDA Î±ÏÏ‡ÎµÎ¯Î± Î±Ï€ÏŒ folder (IDA1 Î® IDA2 Î® IDA3),
    Ï€ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ ÏƒÏ„Î®Î»Î· 'AUCTION' (Ï€.Ï‡. 'IDA1') ÎºÎ±Î¹ Ï†Î¹Î»Ï„ÏÎ¬ÏÎµÎ¹ ÏƒÏ„Î¿ date range.
    Î”Î•Î Î±Î»Î»Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î± Î¿Î½ÏŒÎ¼Î±Ï„Î± Ï„Ï‰Î½ columns Î±Ï€ÏŒ HenEx.
    """
    print(f"ğŸ“‚ Loading {auction_name} from {folder}")
    files = sorted(
        f for f in os.listdir(folder)
        if f.endswith(".xlsx")
    )
    print(f"  â†’ Found {len(files)} files in {auction_name}")

    frames: list[pd.DataFrame] = []

    for fname in files:
        fdate = parse_fname_date(fname)
        if fdate is None:
            continue
        if fdate < start_date or fdate > end_date:
            continue

        full_path = os.path.join(folder, fname)
        print(f"    â€¢ Reading {auction_name} file: {fname}")
        df = pd.read_excel(full_path, engine="openpyxl")

        if "DELIVERY_MTU" not in df.columns:
            print(f"      âš ï¸ No DELIVERY_MTU in {fname}, skipping.")
            continue

        df["DELIVERY_MTU"] = pd.to_datetime(df["DELIVERY_MTU"], errors="coerce")
        df = df.dropna(subset=["DELIVERY_MTU"])

        d_col = df["DELIVERY_MTU"].dt.date
        df = df[(d_col >= start_date) & (d_col <= end_date)]
        if df.empty:
            continue

        df["AUCTION"] = auction_name
        frames.append(df)

    if not frames:
        print(f"  âš ï¸ No rows loaded for {auction_name}")
        return pd.DataFrame()

    out = pd.concat(frames, ignore_index=True)
    print(f"  âœ… Loaded {len(out)} rows for {auction_name}")
    return out


def load_all_idas(idas_root: str,
                  start_date: date,
                  end_date: date) -> pd.DataFrame:
    """
    Î£Ï…Î½Î´Î­ÎµÎ¹ IDA1 / IDA2 / IDA3 ÏƒÎµ Î­Î½Î± DataFrame.
    """
    ida1 = load_ida_folder(os.path.join(idas_root, "IDA1"), "IDA1", start_date, end_date)
    ida2 = load_ida_folder(os.path.join(idas_root, "IDA2"), "IDA2", start_date, end_date)
    ida3 = load_ida_folder(os.path.join(idas_root, "IDA3"), "IDA3", start_date, end_date)

    frames = [df for df in [ida1, ida2, ida3] if not df.empty]
    if not frames:
        print("âš ï¸ No IDA rows at all.")
        return pd.DataFrame()

    all_ida = pd.concat(frames, ignore_index=True)
    print(f"ğŸ“Š Total IDA rows: {len(all_ida)}")
    return all_ida


def load_weather(weather_csv: str) -> pd.DataFrame:
    """
    Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ weather_features CSV.

    Î ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ:
      - Î— Ï€ÏÏÏ„Î· ÏƒÏ„Î®Î»Î· Î½Î± ÎµÎ¯Î½Î±Î¹ datetime index (Ï„Î¿ timestamp Î±Ï€ÏŒ fetch_weather).
    Î¤Î¿ ÎºÎ¬Î½Î¿Ï…Î¼Îµ resample ÏƒÎµ 1H ÎºÎ±Î¹ Î¼ÎµÏ„Î¿Î½Î¿Î¼Î¬Î¶Î¿Ï…Î¼Îµ Î±Ï…Ï„Î® Ï„Î· ÏƒÏ„Î®Î»Î· ÏƒÎµ DELIVERY_MTU
    Î³Î¹Î± merge Î¼Îµ IDM/DAM.
    """
    print(f"ğŸ“‚ Loading weather from {weather_csv}")
    w = pd.read_csv(weather_csv, parse_dates=[0])

    time_col = w.columns[0]
    w = w.rename(columns={time_col: "DELIVERY_MTU"})
    w = w.set_index("DELIVERY_MTU").sort_index()

    # Resample ÏƒÎµ Ï‰ÏÎ¹Î±Î¯Î¿ (1H) Î³Î¹Î± Î½Î± Ï„Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹ Î¼Îµ IDM/DAM
    w_hourly = w.resample("1H").mean().reset_index()

    print(f"âœ… Weather hourly shape: {w_hourly.shape}")
    return w_hourly


# ---------- Main ----------

def main():
    parser = argparse.ArgumentParser(
        description="Build IDM dataset by merging HEnEx DAM, IDA1/2/3 and weather."
    )
    parser.add_argument(
        "--results_root",
        required=True,
        help="Ï€.Ï‡. data/raw/henex/Results2024",
    )
    parser.add_argument(
        "--weather_csv",
        required=True,
        help="Ï€.Ï‡. data/processed/weather_features_15T_2024-06-16_2024-12-31.csv",
    )
    parser.add_argument(
        "--start_date",
        required=True,
        help="YYYY-MM-DD (inclusive), Ï€.Ï‡. 2024-06-16",
    )
    parser.add_argument(
        "--end_date",
        required=True,
        help="YYYY-MM-DD (inclusive), Ï€.Ï‡. 2024-12-31",
    )
    parser.add_argument(
        "--out",
        required=True,
        help="Output CSV path, Ï€.Ï‡. data/processed/idm_dataset_2024.csv",
    )

    args = parser.parse_args()

    start_date = datetime.fromisoformat(args.start_date).date()
    end_date = datetime.fromisoformat(args.end_date).date()

    dam_root = os.path.join(args.results_root, "DAM")
    idas_root = os.path.join(args.results_root, "IDAs")

    # 1) DAM
    dam_all = load_dam_folder(dam_root, start_date, end_date)

    # 2) IDA1/2/3
    ida_all = load_all_idas(idas_root, start_date, end_date)

    if ida_all.empty:
        print("âŒ No IDA data loaded, cannot build dataset.")
        return

    # 3) Weather
    weather = load_weather(args.weather_csv)

    # ----- MERGE -----
    print(f"ğŸ“… IDA rows after date filter [{start_date}, {end_date}]: {ida_all.shape}")

    # Merge IDA + DAM (ÏƒÏ„Î¿ DELIVERY_MTU)
    if not dam_all.empty:
        merged = ida_all.merge(
            dam_all,
            on="DELIVERY_MTU",
            how="left",  # ÎºÏÎ±Ï„Î¬Î¼Îµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ IDA ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚
        )
        print(f"ğŸ”— After merging with DAM: {merged.shape}")
    else:
        print("âš ï¸ No DAM data, continuing with IDA only.")
        merged = ida_all.copy()

    # Merge Î¼Îµ weather
    merged = merged.merge(
        weather,
        on="DELIVERY_MTU",
        how="left",
    )
    print(f"ğŸŒ¦ After merging with weather: {merged.shape}")

    # Save
    os.makedirs(os.path.dirname(args.out), exist_ok=True)
    merged.to_csv(args.out, index=False)
    print(f"âœ… Saved final IDM dataset to: {args.out}")


if __name__ == "__main__":
    main()
